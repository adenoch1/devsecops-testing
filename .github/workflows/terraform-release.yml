name: terraform-release

on:
  workflow_dispatch:
    inputs:
      action:
        description: "Choose what to run"
        required: true
        default: "deploy"
        type: choice
        options: [deploy, destroy]

      container_image_tag:
        description: "Container tag to deploy (run-... or sha-...). Leave empty to use the commit SHA."
        required: false
        default: ""

      two_step_apply:
        description: "Use two-step apply if S3 destination validation occurs"
        required: true
        default: "true"
        type: choice
        options: ["true", "false"]

      smoke_path:
        description: "Path to test on the ALB (example: /health or /)"
        required: true
        default: "/health"
        type: string

permissions:
  id-token: write
  contents: read

concurrency:
  group: terraform-release-${{ github.ref }}
  cancel-in-progress: true

env:
  TF_IN_AUTOMATION: "true"
  TF_INPUT: "false"
  TF_VERSION: "1.6.6"
  WORKDIR: "infra/envs/dev"

jobs:
  ##########################################################
  # DEV (Deploy / Apply) — Gate 1
  ##########################################################
  deploy:
    name: Deploy (dev)
    if: ${{ inputs.action == 'deploy' }}
    runs-on: ubuntu-latest
    environment: dev

    defaults:
      run:
        working-directory: ${{ env.WORKDIR }}

    outputs:
      alb_dns_name: ${{ steps.capture.outputs.alb_dns_name }}
      smoke_path: ${{ steps.capture.outputs.smoke_path }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_APPLY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Verify AWS identity (STS)
        run: aws sts get-caller-identity

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform init
        run: terraform init -input=false

      - name: Resolve container image tag
        id: tag
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${{ inputs.container_image_tag }}" ]; then
            TAG="${{ inputs.container_image_tag }}"
          else
            TAG="${GITHUB_SHA}"
          fi
          echo "tag=$TAG" >> "$GITHUB_OUTPUT"
          echo "Using container_image_tag=$TAG"

      - name: Terraform plan (with image tag)
        run: terraform plan -out=tfplan.binary -var="container_image_tag=${{ steps.tag.outputs.tag }}"

      - name: Terraform apply (fast path)
        id: apply_full
        continue-on-error: true
        run: terraform apply -auto-approve tfplan.binary

      - name: Detect S3 destination validation error
        id: detect_s3_validation
        if: ${{ steps.apply_full.outcome == 'failure' }}
        run: |
          set -euo pipefail
          terraform apply -auto-approve tfplan.binary 2>tf_err.log || true
          if grep -q "Unable to validate the following destination configurations" tf_err.log; then
            echo "hit_validation=true" >> "$GITHUB_OUTPUT"
          else
            echo "hit_validation=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Two-step prime (only if needed and enabled)
        if: ${{ inputs.two_step_apply == 'true' && steps.apply_full.outcome == 'failure' && steps.detect_s3_validation.outputs.hit_validation == 'true' }}
        run: |
          set -euo pipefail
          terraform apply -auto-approve \
            -target=module.logging.aws_kms_key.sqs_sse \
            -target=module.logging.aws_kms_alias.sqs_sse \
            -target=module.logging.aws_sqs_queue.alb_logs_events \
            -target=module.logging.aws_sqs_queue_policy.alb_logs_events \
            -target=module.logging.aws_s3_bucket.alb_logs \
            -target=module.logging.aws_s3_bucket.alb_logs_access \
            -target=module.logging.aws_s3_bucket_policy.alb_logs \
            -target=module.logging.aws_s3_bucket_public_access_block.alb_logs \
            -target=module.logging.aws_s3_bucket_public_access_block.alb_logs_access \
            -target=module.logging.aws_s3_bucket_server_side_encryption_configuration.alb_logs \
            -target=module.logging.aws_s3_bucket_server_side_encryption_configuration.alb_logs_access \
            -target=module.logging.aws_s3_bucket_versioning.alb_logs \
            -target=module.logging.aws_s3_bucket_versioning.alb_logs_access

      - name: Wait for AWS propagation
        if: ${{ inputs.two_step_apply == 'true' && steps.apply_full.outcome == 'failure' && steps.detect_s3_validation.outputs.hit_validation == 'true' }}
        run: sleep 120

      - name: Terraform plan (after prime)
        if: ${{ inputs.two_step_apply == 'true' && steps.apply_full.outcome == 'failure' && steps.detect_s3_validation.outputs.hit_validation == 'true' }}
        run: terraform plan -out=tfplan2.binary -var="container_image_tag=${{ steps.tag.outputs.tag }}"

      - name: Terraform apply (after prime)
        if: ${{ inputs.two_step_apply == 'true' && steps.apply_full.outcome == 'failure' && steps.detect_s3_validation.outputs.hit_validation == 'true' }}
        run: terraform apply -auto-approve tfplan2.binary

      - name: Fail if apply failed for unknown reason
        if: ${{ steps.apply_full.outcome == 'failure' && (steps.detect_s3_validation.outputs.hit_validation != 'true') }}
        run: |
          echo "Terraform apply failed and it was NOT the known S3 destination validation issue."
          exit 1

      # ✅ Robust output capture (auto-detect key)
      - name: Capture and validate Terraform outputs (auto-detect ALB DNS)
        id: capture
        shell: bash
        run: |
          set -euo pipefail

          echo "smoke_path=${{ inputs.smoke_path }}" >> "$GITHUB_OUTPUT"

          # Dump outputs as JSON
          OUT_JSON="$(terraform output -json || true)"
          if [ -z "$OUT_JSON" ] || [ "$OUT_JSON" = "null" ]; then
            echo "ERROR: terraform output -json returned empty."
            exit 1
          fi

          # Try common output keys (in order)
          python - <<'PY'
import json, os, sys
data = json.loads(os.environ["OUT_JSON"])
candidates = [
  "alb_dns_name",
  "alb_dns",
  "alb_fqdn",
  "alb_hostname",
  "load_balancer_dns_name",
  "lb_dns_name",
  "dns_name",
]
def get_value(key):
  v = data.get(key)
  if not v: return None
  # terraform output -json format: { "value": ... }
  if isinstance(v, dict) and "value" in v:
    return v["value"]
  return v

alb = None
picked = None
for k in candidates:
  val = get_value(k)
  if isinstance(val, str) and val.strip():
    alb = val.strip()
    picked = k
    break

if not alb:
  print("ERROR: Could not find an ALB DNS output key.")
  print("Available outputs:", ", ".join(sorted(data.keys())))
  sys.exit(1)

print(f"Found ALB output key: {picked}")
print(f"ALB DNS: {alb}")
# Write to GITHUB_OUTPUT
with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as f:
  f.write(f"alb_dns_name={alb}\n")
PY
        env:
          OUT_JSON: ${{ steps.capture.outputs.OUT_JSON || '' }}
          # pass JSON via env (bash sets it just above)
          OUT_JSON: ${{ '' }}
        # NOTE: github doesn't support dynamic env from previous line; use bash export instead
      - name: Export outputs JSON for python (helper)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          echo "OUT_JSON<<EOF" >> $GITHUB_ENV
          terraform output -json >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      - name: Capture ALB DNS from outputs JSON (final)
        id: capture2
        shell: bash
        run: |
          set -euo pipefail
          echo "smoke_path=${{ inputs.smoke_path }}" >> "$GITHUB_OUTPUT"

          python - <<'PY'
import json, os, sys
data = json.loads(os.environ["OUT_JSON"])
candidates = [
  "alb_dns_name",
  "alb_dns",
  "alb_fqdn",
  "alb_hostname",
  "load_balancer_dns_name",
  "lb_dns_name",
  "dns_name",
]
def get_value(key):
  v = data.get(key)
  if not v: return None
  if isinstance(v, dict) and "value" in v:
    return v["value"]
  return v

alb = None
picked = None
for k in candidates:
  val = get_value(k)
  if isinstance(val, str) and val.strip():
    alb = val.strip()
    picked = k
    break

if not alb:
  print("ERROR: Could not find an ALB DNS output key.")
  print("Available outputs:", ", ".join(sorted(data.keys())))
  sys.exit(1)

print(f"Found ALB output key: {picked}")
print(f"ALB DNS: {alb}")

with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as f:
  f.write(f"alb_dns_name={alb}\n")
PY

      - name: Show ALB URL
        run: |
          echo "ALB DNS: ${{ steps.capture2.outputs.alb_dns_name }}"
          echo "Try: https://${{ steps.capture2.outputs.alb_dns_name }}${{ inputs.smoke_path }}"

    outputs:
      alb_dns_name: ${{ steps.capture2.outputs.alb_dns_name }}
      smoke_path: ${{ inputs.smoke_path }}

  ############################################################
  # DNS — Gate 2
  ############################################################
  dns:
    name: DNS Smoke Test (dns)
    needs: deploy
    runs-on: ubuntu-latest
    environment: dns

    steps:
      - name: Assert ALB DNS is present
        shell: bash
        run: |
          set -euo pipefail
          echo "ALB from deploy outputs: '${{ needs.deploy.outputs.alb_dns_name }}'"
          if [ -z "${{ needs.deploy.outputs.alb_dns_name }}" ]; then
            echo "ERROR: ALB DNS output is empty. Deploy job did not capture terraform outputs correctly."
            exit 1
          fi

      - name: Wait for ALB propagation
        run: sleep 60

      - name: Smoke test (HTTPS first)
        run: |
          set -euo pipefail
          ALB="${{ needs.deploy.outputs.alb_dns_name }}"
          PATH_ONLY="${{ needs.deploy.outputs.smoke_path }}"
          HTTPS_URL="https://${ALB}${PATH_ONLY}"
          echo "Testing: $HTTPS_URL"
          code=$(curl -k -s -o /dev/null -w "%{http_code}" "$HTTPS_URL" || true)
          echo "HTTPS status: $code"
          if [ "$code" != "200" ] && [ "$code" != "301" ] && [ "$code" != "302" ]; then
            echo "Smoke test failed (expected 200/301/302)."
            exit 1
          fi
          echo "Smoke test passed."

  ##########################################################
  # DESTROY — Gate 3 (manual)
  ##########################################################
  destroy:
    name: Destroy (destroy)
    if: ${{ inputs.action == 'destroy' }}
    runs-on: ubuntu-latest
    environment: destroy

    defaults:
      run:
        working-directory: ${{ env.WORKDIR }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_APPLY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Verify AWS identity (STS)
        run: aws sts get-caller-identity

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform init
        run: terraform init -input=false

      - name: Terraform destroy
        run: terraform destroy -auto-approve
