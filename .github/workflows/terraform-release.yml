name: terraform-release

on:
  push:
    branches: ["main"]
    paths:
      - "infra/**/*.tf"
      - "infra/**/terraform.tfvars"
      - ".github/workflows/terraform-release.yml"

  workflow_dispatch:
    inputs:
      action:
        description: "Choose what to run"
        required: true
        default: "deploy"
        type: choice
        options: [deploy, destroy]

      container_image_tag:
        description: "Container tag to deploy (run-.../sha-...). Leave empty to use commit SHA."
        required: false
        default: ""

      two_step_apply:
        description: "Use two-step apply if S3 destination validation occurs"
        required: true
        default: "true"
        type: choice
        options: ["true", "false"]

      teardown_after_test:
        description: "If true, destroy after DNS smoke test (manual runs only)"
        required: true
        default: "false"
        type: choice
        options: ["true", "false"]

      smoke_path:
        description: "HTTP path to test on the ALB (example: /health or /)"
        required: true
        default: "/health"
        type: string

permissions:
  id-token: write
  contents: read

concurrency:
  group: terraform-release-${{ github.ref }}
  cancel-in-progress: true

env:
  TF_IN_AUTOMATION: "true"
  TF_INPUT: "false"
  TF_VERSION: "1.6.6"
  WORKDIR: "infra/envs/dev"

jobs:
  ############################################################
  # DEV (Deploy / Apply) — Gate 1
  ############################################################
  deploy:
    name: Deploy (dev)
    if: ${{ github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.action == 'deploy') }}
    runs-on: ubuntu-latest
    environment: dev

    defaults:
      run:
        working-directory: ${{ env.WORKDIR }}

    outputs:
      alb_dns_name: ${{ steps.capture.outputs.alb_dns_name }}
      smoke_path: ${{ steps.resolved.outputs.smoke_path }}
      teardown_after_test: ${{ steps.resolved.outputs.teardown_after_test }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_APPLY }}
          aws-region: ${{ secrets.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Verify AWS identity (STS)
        run: aws sts get-caller-identity

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform init
        run: terraform init -input=false

      - name: Resolve inputs (tag / smoke / teardown / two-step)
        id: resolved
        shell: bash
        run: |
          set -euo pipefail

          TAG=""
          SMOKE="/health"
          TEARDOWN="false"
          TWO_STEP="true"

          # Push to main: default tag = commit SHA, keep defaults for others
          if [ "${{ github.event_name }}" = "push" ]; then
            TAG="${GITHUB_SHA}"
          fi

          # Manual dispatch: obey inputs
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            TAG="${{ inputs.container_image_tag }}"
            SMOKE="${{ inputs.smoke_path }}"
            TEARDOWN="${{ inputs.teardown_after_test }}"
            TWO_STEP="${{ inputs.two_step_apply }}"
          fi

          # If no tag provided manually, fall back to commit SHA
          if [ -z "$TAG" ]; then
            TAG="${GITHUB_SHA}"
          fi

          echo "container_image_tag=$TAG" >> "$GITHUB_OUTPUT"
          echo "smoke_path=$SMOKE" >> "$GITHUB_OUTPUT"
          echo "teardown_after_test=$TEARDOWN" >> "$GITHUB_OUTPUT"
          echo "two_step_apply=$TWO_STEP" >> "$GITHUB_OUTPUT"

          echo "Resolved:"
          echo "  container_image_tag=$TAG"
          echo "  smoke_path=$SMOKE"
          echo "  teardown_after_test=$TEARDOWN"
          echo "  two_step_apply=$TWO_STEP"

      - name: Terraform plan (full)
        run: terraform plan -out=tfplan.binary -var="container_image_tag=${{ steps.resolved.outputs.container_image_tag }}"

      - name: Terraform apply (full - fast path)
        id: apply_full
        continue-on-error: true
        run: terraform apply -auto-approve tfplan.binary

      - name: Detect S3 destination validation error
        id: detect_s3_validation
        if: ${{ steps.apply_full.outcome == 'failure' }}
        shell: bash
        run: |
          set -euo pipefail
          terraform apply -auto-approve tfplan.binary 2>tf_err.log || true
          if grep -q "Unable to validate the following destination configurations" tf_err.log; then
            echo "hit_validation=true" >> "$GITHUB_OUTPUT"
          else
            echo "hit_validation=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Terraform apply (step 1 - prime S3->SQS prereqs)
        if: |
          steps.resolved.outputs.two_step_apply == 'true' &&
          steps.apply_full.outcome == 'failure' &&
          steps.detect_s3_validation.outputs.hit_validation == 'true'
        shell: bash
        run: |
          set -euo pipefail
          terraform apply -auto-approve \
            -target=module.logging.aws_kms_key.sqs_sse \
            -target=module.logging.aws_kms_alias.sqs_sse \
            -target=module.logging.aws_sqs_queue.alb_logs_events \
            -target=module.logging.aws_sqs_queue_policy.alb_logs_events \
            -target=module.logging.aws_s3_bucket.alb_logs \
            -target=module.logging.aws_s3_bucket.alb_logs_access \
            -target=module.logging.aws_s3_bucket_policy.alb_logs \
            -target=module.logging.aws_s3_bucket_public_access_block.alb_logs \
            -target=module.logging.aws_s3_bucket_public_access_block.alb_logs_access \
            -target=module.logging.aws_s3_bucket_server_side_encryption_configuration.alb_logs \
            -target=module.logging.aws_s3_bucket_server_side_encryption_configuration.alb_logs_access \
            -target=module.logging.aws_s3_bucket_versioning.alb_logs \
            -target=module.logging.aws_s3_bucket_versioning.alb_logs_access

      - name: Wait for AWS propagation
        if: |
          steps.resolved.outputs.two_step_apply == 'true' &&
          steps.apply_full.outcome == 'failure' &&
          steps.detect_s3_validation.outputs.hit_validation == 'true'
        run: sleep 120

      - name: Terraform plan (after prime)
        if: |
          steps.resolved.outputs.two_step_apply == 'true' &&
          steps.apply_full.outcome == 'failure' &&
          steps.detect_s3_validation.outputs.hit_validation == 'true'
        run: terraform plan -out=tfplan2.binary -var="container_image_tag=${{ steps.resolved.outputs.container_image_tag }}"

      - name: Terraform apply (after prime)
        if: |
          steps.resolved.outputs.two_step_apply == 'true' &&
          steps.apply_full.outcome == 'failure' &&
          steps.detect_s3_validation.outputs.hit_validation == 'true'
        run: terraform apply -auto-approve tfplan2.binary

      - name: Fail if apply failed for unknown reason
        if: ${{ steps.apply_full.outcome == 'failure' && (steps.detect_s3_validation.outputs.hit_validation != 'true') }}
        run: |
          echo "Terraform apply failed and it was NOT the known S3 destination validation issue."
          exit 1

      # ✅ Robust capture of ALB DNS output (auto-detect key + fail fast)
      - name: Capture ALB DNS output (robust)
        id: capture
        shell: bash
        run: |
          set -euo pipefail

          echo "Terraform outputs available:"
          terraform output || true

          OUT_JSON="$(terraform output -json)"
          python3 - <<'PY'
import json, os, sys

data = json.loads(os.environ["OUT_JSON"])

def val(k):
  x = data.get(k)
  if not x:
    return None
  if isinstance(x, dict) and "value" in x:
    return x["value"]
  return x

candidates = [
  "alb_dns_name",
  "alb_dns",
  "alb_fqdn",
  "alb_hostname",
  "load_balancer_dns_name",
  "lb_dns_name",
  "dns_name",
]

alb = None
picked = None
for k in candidates:
  v = val(k)
  if isinstance(v, str) and v.strip():
    alb = v.strip()
    picked = k
    break

if not alb:
  print("ERROR: Could not find ALB DNS output. Available outputs:")
  print(", ".join(sorted(data.keys())))
  sys.exit(1)

print(f"Found ALB output key: {picked}")
print(f"ALB DNS: {alb}")

with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as f:
  f.write(f"alb_dns_name={alb}\n")
PY
        env:
          OUT_JSON: ${{ steps.capture.outputs.OUT_JSON || '' }}

      - name: Show ALB URL
        run: |
          echo "ALB DNS: ${{ steps.capture.outputs.alb_dns_name }}"
          echo "HTTPS: https://${{ steps.capture.outputs.alb_dns_name }}${{ steps.resolved.outputs.smoke_path }}"
          echo "HTTP : http://${{ steps.capture.outputs.alb_dns_name }}${{ steps.resolved.outputs.smoke_path }}"

  ############################################################
  # DNS — Gate 2
  ############################################################
  dns:
    name: DNS Smoke Test (dns)
    needs: deploy
    if: ${{ needs.deploy.result == 'success' }}
    runs-on: ubuntu-latest
    environment: dns

    steps:
      - name: Assert ALB DNS is present
        shell: bash
        run: |
          set -euo pipefail
          echo "ALB from deploy outputs: '${{ needs.deploy.outputs.alb_dns_name }}'"
          if [ -z "${{ needs.deploy.outputs.alb_dns_name }}" ]; then
            echo "ERROR: ALB DNS output is empty from deploy job."
            exit 1
          fi

      - name: Wait for ALB propagation
        run: sleep 60

      - name: Smoke test (HTTPS then HTTP)
        shell: bash
        run: |
          set -euo pipefail
          ALB="${{ needs.deploy.outputs.alb_dns_name }}"
          PATH_ONLY="${{ needs.deploy.outputs.smoke_path }}"

          HTTPS_URL="https://${ALB}${PATH_ONLY}"
          HTTP_URL="http://${ALB}${PATH_ONLY}"

          echo "Testing HTTPS: $HTTPS_URL"
          code=$(curl -k -s -o /dev/null -w "%{http_code}" "$HTTPS_URL" || true)
          echo "HTTPS status: $code"
          if [ "$code" = "200" ] || [ "$code" = "301" ] || [ "$code" = "302" ]; then
            echo "Smoke test passed on HTTPS."
            exit 0
          fi

          echo "Testing HTTP: $HTTP_URL"
          code=$(curl -s -o /dev/null -w "%{http_code}" "$HTTP_URL" || true)
          echo "HTTP status: $code"
          if [ "$code" = "200" ] || [ "$code" = "301" ] || [ "$code" = "302" ]; then
            echo "Smoke test passed on HTTP."
            exit 0
          fi

          echo "Smoke test failed (expected 200/301/302)."
          exit 1

  ##########################################################
  # DESTROY — Gate 3 (manual teardown option)
  ##########################################################
  destroy:
    name: Destroy (destroy)
    needs: dns
    if: ${{ github.event_name == 'workflow_dispatch' && (inputs.action == 'destroy' || needs.deploy.outputs.teardown_after_test == 'true') }}
    runs-on: ubuntu-latest
    environment: destroy

    defaults:
      run:
        working-directory: ${{ env.WORKDIR }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_APPLY }}
          aws-region: ${{ secrets.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Verify AWS identity (STS)
        run: aws sts get-caller-identity

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform init
        run: terraform init -input=false

      - name: Terraform destroy
        run: terraform destroy -auto-approve
